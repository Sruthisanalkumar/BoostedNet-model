# -*- coding: utf-8 -*-
"""DeepHP_BoosedNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sy4ZDnQOYKDEd9jcszThippmY2iwqBm1

# Helicobacter detection using CNN + XGBoost
# Author : Sruthi Krishna
# Dataset Deep HP
## Number of images
## Table of Contents
- [1 - Library Functions](#1)
- [2 - Loading Dataset](#2)
- [3 - Splitting, Preprocessing and Visualization of images](#3)
- [4 - Proposed CNN model](#4)
- [5 - Training and validation of CNN](#5)
- [6 - Gradient-weighted Class Activation Mapping](#6)
- [7 - XG Boost](#7)
- [8 - XG Boost validation](#8)
- [9 - Evaluation on images](#9)
- [10 - CNN Reference models Evaluation](#10)

<a name='1'></a>
# 1 - Library functions
"""

import numpy as np # for numerical computing in Python
import os #for interacting with the file system
#import pickle # for serializing and deserializing Python objects
import keras
from scipy import stats #for statistics
import tensorflow as tf
import xgboost as xgb #gradient boosting library for Python
from datetime import datetime #for working with dates and times in Python
from sklearn.metrics import accuracy_score,confusion_matrix, precision_score,recall_score,roc_curve#for evaluating machine learning models
from keras.models import Sequential
from keras.utils import to_categorical
from keras.preprocessing.image import ImageDataGenerator
from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras import optimizers
from keras import regularizers
from keras.callbacks import LearningRateScheduler
import cv2 #for image reading
import warnings
warnings.filterwarnings('ignore') # for issuing warnings to the user
from keras.models import model_from_json
from google.colab.patches import cv2_imshow
import math #for mathematical model
import matplotlib.pyplot as plt # for ploting
import shutil #for high-level file operations such as copying and moving files
import glob #for searching for files in a directory based on a pattern
from PIL import Image #for working with images in Python
from keras.applications.mobilenet import MobileNet, preprocess_input
from keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense, BatchNormalization,GlobalAvgPool2D
from keras.models import Sequential
from PIL import Image
#from keras.preprocessing.image import load_model
import pickle

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.preprocessing.image import load_img, img_to_array
from keras.models import load_model

from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Install the PyDrive library
!pip install PyDrive #to use drive credentials

# Authenticate and create the PyDrive client
from google.colab import auth
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from oauth2client.client import GoogleCredentials

import os
import shutil
from tensorflow.keras.models import Sequential
from tensorflow.keras.applications import InceptionV3
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from keras.callbacks import ModelCheckpoint, EarlyStopping
from sklearn.metrics import roc_auc_score, roc_curve

import numpy as np
import tensorflow as tf
from tensorflow import keras

# Display
from IPython.display import Image, display
import matplotlib.pyplot as plt
import matplotlib.cm as cm
import matplotlib.image as mpimg

"""<a name='2'></a>
# 2 - Load dataset

## Importing Giemsa Stained Images
"""

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

# Get the ID of the zip file from Google Drive
file_id = '1iXW69Mz'

# Download the zip file to Google Colab
downloaded = drive.CreateFile({'id': file_id})
downloaded.GetContentFile('/dataset/deephp.zip')


!unzip '/dataset/deephp.zip'

import cv2

def apply_noise_filter(image):
    # Apply Gaussian smoothing
    filtered_image = cv2.GaussianBlur(image, (5, 5), 0)

    return filtered_image

# Assuming you have a dataset of images stored in a directory
dataset_directory = "/content/dataset"

# Iterate through the images in the dataset directory
for image_file in os.listdir(dataset_directory):
    if image_file.endswith(".jpg") or image_file.endswith(".png"):
        # Load the image
        image_path = os.path.join(dataset_directory, image_file)
        image = cv2.imread(image_path)

        # Apply noise filter
        filtered_image = apply_noise_filter(image)

        # Save the filtered image
        filtered_image_path = os.path.join(dataset_directory, image_file)
        cv2.imwrite(filtered_image_path, filtered_image)

"""<a name='3'></a>
# 3 - Splitting, Preprocessing and Visualization of images

### Giemsa images
"""

# count the number of images in respective classes 0- unaffected, 1 infected
ROOT_DIR = '/content/dataset/deephp'
number_of_images={}

for dir in os.listdir(ROOT_DIR):
  number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))

# train folder
def datafolder(p, split):
  if not os.path.exists("./"+p):
    os.mkdir("./"+p)
    for dir in os.listdir(ROOT_DIR):
      os.makedirs("./"+p+"/"+dir)
      for img in np.random.choice(a=os.listdir(os.path.join(ROOT_DIR,dir)),size=(math.floor(split*number_of_images[dir])-2),replace=False):
        o = os.path.join(ROOT_DIR,dir,img)#path
        D = os.path.join("./"+p,dir)
        shutil.copy(o,D)
        os.remove(o)

  else:
    print(f"{path}Train Folder exists")

datafolder("train1", .7)
datafolder("val1", .15)
datafolder("test1", .15)

"""## Data Pre-Processing
### Data augmentation for Training dataset
- Rotation Range
- Zoom Range
- Shear Range
- Horizontal Flip
- Vertical Flip
- Rescale
"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

def preprocessingImages(path):

    # Define the augmentation parameters
    image_data = ImageDataGenerator(
        rotation_range=20,  # Randomly rotate images within the range of [-20, 20] degrees
        zoom_range=0.2,     # Randomly zoom images by 20%
        shear_range=0.2,    # Randomly apply shear transformations
        horizontal_flip=True,  # Randomly flip images horizontally
        vertical_flip=True,    # Randomly flip images vertically
        rescale=1/255       # Normalize the image pixel values to the range [0, 1]
    )

    # Load and preprocess images
    image = image_data.flow_from_directory(
        directory=path,
        target_size=(256, 256),
        batch_size=50,
        class_mode='binary'
    )

    return image

path = '/content/train1'
train_data1 = preprocessingImages(path)

#validation
def preprocessingImgaes1(path):

  image_data =ImageDataGenerator(rescale= 1/255)
  image = image_data.flow_from_directory(directory = path, target_size = (256,256),batch_size=50,class_mode =  'binary')

  return image

path = '/content/val1'
validation_data1 = preprocessingImgaes1(path)

path = '/content/test1'
test_data1 = preprocessingImgaes1(path)

"""## Visulization of images"""

def show_batch(image_batch, label_batch):
    plt.figure(figsize=(10,10))
    for n in range(15):
        ax = plt.subplot(5,5,n+1)
        plt.imshow(image_batch[n])
        if(label_batch[n]==0):
          title = 'negative'
        else:
          title = 'positive'
        plt.title(title)
        #plt.tittle(number_of_images)
        plt.axis("off")

## Geimsa Stained images
image_batch, label_batch = next(iter(validation_data1))
#print(label_batch)
show_batch(image_batch, label_batch)


from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPool2D, Dropout, Flatten, Dense

model = Sequential()
model.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu', input_shape=(256, 256, 3)))

model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))

model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))

model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
model.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))

model.add(Dropout(rate=0.25))

model.add(Flatten())
model.add(Dense(units=64, activation='relu'))
model.add(Dropout(rate=0.25))
model.add(Dense(units=256, activation='relu'))
model.add(Dense(units=1, activation='sigmoid'))

model.summary()
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',
        keras.metrics.Precision(name="precision"),
        keras.metrics.Recall(name="recall")])

#Earlystopping and model check point

from keras.callbacks import ModelCheckpoint, EarlyStopping

#early stopping
es = EarlyStopping(monitor="val_accuracy",min_delta=0.01, patience = 20, verbose = 1, mode ='auto')

#model check point
mc = ModelCheckpoint(monitor="val_accuracy",filepath="/DeepHp model/cnn_6layer.h5",verbose=1, save_best_only=True, mode="auto")
cd =[es,mc]
gs = model.fit_generator(generator=train_data1, steps_per_epoch=8,epochs=100, verbose=1, validation_data=validation_data1,validation_steps =16, callbacks = cd)
model.save("/DeepHp model/cnn_6layer_100 epochs.h5")

model=load_model("/DeepHp model/cnn_6layer_100 epochs.h5")

#Testing of Model
acc = model.evaluate_generator(validation_data1)[1]

print(f"The accuracy of model is {acc*100}%")

# count the number of images in respective classes 0- unaffected, 1 infected
ROOT_DIR = '/content/test1'
number_of_images={}

for dir in os.listdir(ROOT_DIR):
     number_of_images[dir] = len(os.listdir(os.path.join(ROOT_DIR,dir)))

#For taking True values
import os
import numpy as np

# Define the paths to the positive and negative image folders
positive_folder = "/content/test1/positive"
negative_folder = "/content/test1/negative"

# Get the list of files in each folder
positive_files = os.listdir(positive_folder)
negative_files = os.listdir(negative_folder)

# Create an array to store the labels
y_true= []

# Append 1 for positive images and 0 for negative images
for _ in positive_files:
    y_true.append(1)

for _ in negative_files:
    y_true.append(0)

# Convert the labels list to a NumPy array
y_true = np.array(y_true)

print(y_true)

len(y_true)

# for taking predictions
import numpy as np

y_pred_1 = []  # Initialize an empty list to store predictions

def testimage(path):
    img = load_img(path, target_size=(256, 256))
    input_arr = img_to_array(img) / 255

    input_arr = np.expand_dims(input_arr, axis=0)
    y_pred = model.predict(input_arr)
    #y_pred = (y_pred_prob > 0.5).astype(int)

    y_pred_1.append(y_pred)
    #y_pred = np.array(y_pred_list_1)

# Set the directory containing the images
#for negative images
directory = "/content/test1/positive"

# Loop through each file in the directory
for filename in os.listdir(directory):

    # Check if the file is a supported image format
    if filename.endswith(".jpeg") or filename.endswith(".png"):

        # Get the full path of the image
        filepath = os.path.join(directory, filename)
        testimage(filepath)
        #testimage1(filepath,'negative')
        # Print the filepath
        #print(filepath)

y_pred_1
y_pred = np.array(y_pred_1)

# Flatten the array to convert it to a normal array
y_pred = y_pred.flatten()
y_pred

y_pred1 = [0 if val < 0.5 else 1 for val in y_pred]

print("Complementary array:", y_pred1)

len(y_pred1)

# for taking predictions
import numpy as np

y_pred_2 = []  # Initialize an empty list to store predictions

def testimage2(path):
    img = load_img(path, target_size=(256, 256))
    input_arr = img_to_array(img) / 255

    input_arr = np.expand_dims(input_arr, axis=0)
    y_prd = model.predict(input_arr)
    #y_pred = (y_pred_prob > 0.5).astype(int)

    y_pred_2.append(y_prd)
    #y_pred = np.array(y_pred_list_1)

# Set the directory containing the images
#for negative images
directory = "/content/test1/negative"

# Loop through each file in the directory
for filename in os.listdir(directory):

    # Check if the file is a supported image format
    if filename.endswith(".jpeg") or filename.endswith(".png"):

        # Get the full path of the image
        filepath = os.path.join(directory, filename)
        testimage2(filepath)
        #testimage1(filepath,'negative')
        # Print the filepath
        #print(filepath)

y_pred_2
y_predc = np.array(y_pred_2)

# Flatten the array to convert it to a normal array
y_predc = y_predc.flatten()
y_predc

len(y_predc)

len(y_pred_2)

y_predf = np.concatenate((y_pred, y_predc))
len(y_predf)

y_predb = [0 if val < 0.5 else 1 for val in y_predf]

print("Complementary array:", y_predb)

len(y_predb)

import numpy as np



# Find indices where predictions match the true labels
correctly_classified_indices = np.where(y_true == y_predb)[0]

# Find indices where predictions do not match the true labels
wrongly_classified_indices = np.where(y_true != y_predb)[0]

# Print or use the indices as needed
print("Correctly classified indices:", correctly_classified_indices)
print("Wrongly classified indices:", wrongly_classified_indices)

# Access corresponding samples if needed
correctly_classified_samples = y_true[correctly_classified_indices]
wrongly_classified_samples = y_true[wrongly_classified_indices]

import seaborn as sns
cm = confusion_matrix(y_true, y_predb)

# Plot confusion matrix
labels = np.unique(y_true)  # Get unique class labels
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
cm = confusion_matrix(y_true, y_predb)

tn, fp, fn, tp = cm.ravel()

# Print the values
print("True Negatives (TN):", tn)
print("False Positives (FP):", fp)
print("False Negatives (FN):", fn)
print("True Positives (TP):", tp)

import math
ACCURACY = (tp+tn)/((tp+tn+fp+fn))
PRECISION = tp/(tp+fp)
RECALL = tp/(tp+fn)
F1_SCORE = 2*tp/(2*tp+fn+fp)
MCC = ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))
print("Accuracy= ",ACCURACY*100)
print("Precision= ",PRECISION*100)
print("Recall = ",RECALL*100)
print("F1_score = ",F1_SCORE*100)
print("Mthews Correlation Coeffieicent = ",MCC*100)
specificity = tn / (tn + fp)

# Assuming 'y_true' contains the true labels and 'y_pred' contains the predicted probabilities
auc = roc_auc_score(y_true, y_predb)
fpr, tpr, thresholds = roc_curve(y_true, y_predb)

# Plot ROC curve
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.grid(True)
plt.legend()
plt.show()

from sklearn.metrics import matthews_corrcoef

import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve

# y_true: true labels (0 for negative, 1 for positive)
# y_pred: predicted probabilities of the positive class

precision, recall, thresholds = precision_recall_curve(y_true, y_predf)

# Remove the last threshold and corresponding precision and recall values
precision = precision[:-1]
recall = recall[:-1]

# Plot the precision-recall curve
plt.plot(recall, precision)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.grid(True)
#plt.legend()
plt.show()

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precision, recall, thresholds = precision_recall_curve(y_true, y_predf)

plt.plot(thresholds, precision[:-1], label='Precision')

plt.xlabel('Threshold')
plt.ylabel('Precision')
plt.legend()
plt.title('Precision vs confidence Curve')
plt.grid(True)
plt.show()

plt.plot(thresholds, recall[:-1], label='Recall')
plt.xlabel('Threshold')
plt.ylabel('Recall')
plt.legend()
plt.title('Recall vs confidence Curve')
plt.grid(True)
plt.show()

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precision, recall, thresholds = precision_recall_curve(y_true, y_predb)

plt.plot(thresholds, precision[:-1], label='Precision')

plt.xlabel('Threshold')
plt.ylabel('Precision')
plt.legend()
plt.title('Precision vs confidence Curve')
plt.grid(False)
plt.show()
"""

#Graphical Interpretation
#Model Graphical interpretetion
g = gs.history
g.keys()

import matplotlib.pyplot as plt
# plt.plot(h['accuracy'])
# plt.plot(h['val_accuracy'],c='red')
plt.plot(g['accuracy'],'y',label='Training accuracy')
plt.plot(g['val_accuracy'],'r',label='Validation accuracy')
plt.title('Training and Validation accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

import matplotlib.pyplot as plt
# plt.plot(h['accuracy'])
# plt.plot(h['val_accuracy'],c='red')
plt.plot(g['loss'],'y',label='Training loss')
plt.plot(g['val_loss'],'r',label='Validation loss')
plt.title('Training and Validation loss')
plt.xlabel('Epochs')
plt.ylabel('loss')
plt.legend()
plt.show()

weights = model.get_weights()

# Save the weights to a file
np.save('/DeepHP/DeepHp_100 epochs_weights.npy', weights)
#print(weights)

"""##GradCAM"""

def get_img_array(img_path, size):
    # `img` is a PIL image of size 299x299
    img = keras.preprocessing.image.load_img(img_path, target_size=size)
    # `array` is a float32 Numpy array of shape (299, 299, 3)
    array = keras.preprocessing.image.img_to_array(img)
    # We add a dimension to transform our array into a "batch"
    # of size (1, 299, 299, 3)
    array = np.expand_dims(array, axis=0)
    return array


def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # First, we create a model that maps the input image to the activations
    # of the last conv layer as well as the output predictions
    grad_model = tf.keras.models.Model(
        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Then, we compute the gradient of the top predicted class for our input image
    # with respect to the activations of the last conv layer
    with tf.GradientTape() as tape:
        last_conv_layer_output, preds = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(preds[0])
        class_channel = preds[:, pred_index]

    # This is the gradient of the output neuron (top predicted or chosen)
    # with regard to the output feature map of the last conv layer
    grads = tape.gradient(class_channel, last_conv_layer_output)

    # This is a vector where each entry is the mean intensity of the gradient
    # over a specific feature map channel
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # We multiply each channel in the feature map array
    # by "how important this channel is" with regard to the top predicted class
    # then sum all the channels to obtain the heatmap class activation
    last_conv_layer_output = last_conv_layer_output[0]
    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # For visualization purpose, we will also normalize the heatmap between 0 & 1
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)
    return heatmap.numpy()

def save_and_display_gradcam(img_path, heatmap, cam_path="cam.jpg", alpha=0.4):
    # Load the original image
    img = keras.preprocessing.image.load_img(img_path)
    img = keras.preprocessing.image.img_to_array(img)

    # Rescale heatmap to a range 0-255
    heatmap = np.uint8(255 * heatmap)

    # Use jet colormap to colorize heatmap
    jet = cm.get_cmap("jet")

    # Use RGB values of the colormap
    jet_colors = jet(np.arange(256))[:, :3]
    jet_heatmap = jet_colors[heatmap]

    # Create an image with RGB colorized heatmap
    jet_heatmap = keras.preprocessing.image.array_to_img(jet_heatmap)
    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))
    jet_heatmap = keras.preprocessing.image.img_to_array(jet_heatmap)

    # Superimpose the heatmap on original image
    superimposed_img = jet_heatmap * alpha + img
    superimposed_img = keras.preprocessing.image.array_to_img(superimposed_img)

    # Save the superimposed image
    superimposed_img.save(cam_path)
    image = Image.open(cam_path)

    # Show the image
    image.show()
    # Display Grad CAM
    #display(Image(cam_path))

import matplotlib.pyplot as plt
from matplotlib import cm

def Grad(path,last_conv_layer_name):
  #size = (256,256,3)
  img_array = get_img_array(path, (256,256,3))
  weights= '/content/drive/MyDrive/gastric histopathology/weights/DeepHP/DeepHp_100 epochs_weights.npy'
  model.layers[-1].activation = None
  preds = model.predict(img_array)
  heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)
  image = Image.open(path)
  print("Real Images")
  display(image)

  # Display heatmap
  #cv2_imshow('')
  print("Heat map")
  plt.matshow(heatmap)
  plt.show()
  heatmap_path = "heatmap.jpg"
  superimposed_path = "superimposed.jpg"
  save_and_display_gradcam(path, heatmap, cam_path=superimposed_path)
  plt.savefig(heatmap_path)

  # Display superimposed image
  print("Superimposed image")
  superimposed_image = Image.open(superimposed_path)
  display(superimposed_image)

  # Display heatmap and superimposed image
  # heatmap_image = Image.open(heatmap_path)
  # display(heatmap_image)

"""##For negative image"""

from PIL import Image

model.summary()

path = '/content/hpylori (1).jpg'
print("In last Convolution layer")
Grad(path,'conv2d_5')

"""

import numpy as np
import xgboost as xgb
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator

image_data = ImageDataGenerator(rescale=1./255)
batch_size = 32

train_generator = image_data.flow_from_directory(
    directory='/content/train1',
    target_size=(256, 256),
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)


test_generator = image_data.flow_from_directory(
    directory='/content/test1',
    target_size=(256, 256),
    batch_size=batch_size,
    class_mode='binary',
    shuffle=False
)

# Extract features from the pre-trained CNN model
train_features = model.predict(train_generator)
test_features = model.predict(test_generator)

# Flatten the features
train_features_flat = np.reshape(train_features, (train_features.shape[0], -1))
test_features_flat = np.reshape(test_features, (test_features.shape[0], -1))

# True labels
train_labels = train_generator.classes
test_labels = test_generator.classes

# Train XGBoost model using the extracted features
xgb_model = xgb.XGBClassifier(
    n_estimators=100,
    max_depth=3,
    learning_rate=0.1,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
xgb_model.fit(train_features_flat, train_labels)

# Evaluate XGBoost model
accuracy = xgb_model.score(test_features_flat, test_labels)
print("Accuracy:", accuracy*100)

accuracy = xgb_model.score(train_features_flat, train_labels)
print("Accuracy:", accuracy*100)

pred = xgb_model.predict(test_features_flat)

import seaborn as sns
cm = confusion_matrix(test_labels, pred)

# Plot confusion matrix
labels = np.unique(test_labels)  # Get unique class labels
sns.heatmap(cm, annot=True, cmap='Blues', fmt='d', xticklabels=labels, yticklabels=labels)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()
cm = confusion_matrix(test_labels, pred)

tn, fp, fn, tp = cm.ravel()

# Print the values
print("True Negatives (TN):", tn)
print("False Positives (FP):", fp)
print("False Negatives (FN):", fn)
print("True Positives (TP):", tp)

import math
ACCURACY = (tp+tn)/((tp+tn+fp+fn))
PRECISION = tp/(tp+fp)
RECALL = tp/(tp+fn)
F1_SCORE = 2*tp/(2*tp+fn+fp)
MCC = ((tp*tn)-(fp*fn))/math.sqrt((tp+fp)*(tp+fn)*(tn+fp)*(tn+fn))
print("Accuracy= ",ACCURACY*100)
print("Precision= ",PRECISION*100)
print("Recall = ",RECALL*100)
print("F1_score = ",F1_SCORE*100)
print("Mthews Correlation Coeffieicent = ",MCC*100)


# Assuming 'y_true' contains the true labels and 'y_pred' contains the predicted probabilities
auc = roc_auc_score(test_labels, pred)
fpr, tpr, thresholds = roc_curve(test_labels, pred)

# Plot ROC curve
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.grid(True)
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.show()

from sklearn.metrics import matthews_corrcoef

# Assuming 'y_true' contains the true labels and 'y_pred' contains the predicted classes
mcc = matthews_corrcoef(test_labels, pred)
mcc

from sklearn.metrics import precision_recall_curve
precision, recall, thresholds = precision_recall_curve(test_labels, test_features_flat)

# Remove the last threshold and corresponding precision and recall values
precision = precision[:-1]
recall = recall[:-1]

# Plot the precision-recall curve
plt.plot(recall, precision)
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve-Boosted-Net')
plt.grid(True)
#plt.legend()
plt.show()

from sklearn.metrics import precision_recall_curve
import matplotlib.pyplot as plt

precision, recall, thresholds = precision_recall_curve(y_true, y_predf)

plt.plot(thresholds, precision[:-1], label='Precision')

plt.xlabel('Threshold')
plt.ylabel('Precision')
plt.legend()
plt.title('Precision vs confidence Curve')
plt.grid(True)
plt.show()
